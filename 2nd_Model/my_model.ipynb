{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nba_api.stats.static import teams\n",
    "from nba_api.stats.endpoints import leaguegamefinder\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from os import path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_teams = teams.get_teams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This portion retreives all the scratch data using NBA API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(filename, start_date, end_date):\n",
    "    if (path.exists(filename) != True):\n",
    "        \n",
    "        team_id = nba_teams[0]['id']\n",
    "        gamefinder = leaguegamefinder.LeagueGameFinder(date_from_nullable = start_date , date_to_nullable = end_date , team_id_nullable = team_id)\n",
    "        games = gamefinder.get_data_frames()[0]\n",
    "        games.to_csv(filename,index=False)\n",
    "        \n",
    "    if (path.exists(filename) == True):   \n",
    "        \n",
    "        old_df = pd.read_csv(filename)\n",
    "        last_id = old_df['TEAM_ID'][len(old_df)-1]\n",
    "        start_id = int(last_id) + 1\n",
    "        \n",
    "        while start_id <= 1610612766:\n",
    "            old_df = pd.read_csv(filename)\n",
    "            gamefinder = leaguegamefinder.LeagueGameFinder(date_from_nullable = start_date , date_to_nullable = end_date , team_id_nullable = start_id)\n",
    "            games = gamefinder.get_data_frames()[0]\n",
    "            new_df = old_df.append(games)\n",
    "            new_df.to_csv(filename, index=False)\n",
    "            start_id = start_id + 1\n",
    "def error_handle(count, filename, start_date, end_date):\n",
    "    try:\n",
    "        print(\"-----try is running-----\")\n",
    "        # put csv name here\n",
    "        getData(filename, start_date, end_date)\n",
    "        count = 0\n",
    "        \n",
    "    except:\n",
    "        if count < 25:\n",
    "            print(\"-----exception handled-----\", count)\n",
    "            error_handle(count + 1,filename, start_date, end_date)\n",
    "        else:\n",
    "            print(\"-----max tries exceeded-----\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finds the ten day rolling averages per team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#name of csv to read, name of csv to write\n",
    "def rolling_average_stats(r_filename, w_filename):  \n",
    "    csv_df = pd.read_csv(r_filename)\n",
    "\n",
    "    list_points = []\n",
    "    list_team_points = []\n",
    "    x = 1\n",
    "    for team in nba_teams:\n",
    "        team_df = csv_df[csv_df['TEAM_ID'] == team['id']]\n",
    "        for col in team_df.columns[9:]:\n",
    "            team_df['AV_'+ col] = team_df[col].rolling(window=10).mean()\n",
    "            team_df['AV_'+ col] = team_df['AV_'+ col].shift(1) #add code here\n",
    "        head = list(team_df.columns.values)\n",
    "        if x == 1:\n",
    "#             new_df = team_df\n",
    "            team_df.to_csv(w_filename, header=head, index=False)\n",
    "            x = x+1\n",
    "\n",
    "        else:\n",
    "#             new_df.append(team_df)\n",
    "            team_df.to_csv(w_filename, mode='a', header=False, index=False)\n",
    "rolling_average_stats('correct_dates_19-20.csv', 'ten_day-19-20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#name of csv to read, name of csv to write\n",
    "def most_recent_team_data(r_filename, w_filename, start_date, end_date):  \n",
    "    \n",
    "    error_handle(0,r_filename,start_date, end_date)\n",
    "    csv_df = pd.read_csv(r_filename)\n",
    "    csv_df = csv_df.sort_values(['TEAM_ABBREVIATION','GAME_DATE'] , ascending=[True, True])\n",
    "\n",
    "    list_points = []\n",
    "    list_team_points = []\n",
    "    x = 1\n",
    "    for team in nba_teams:\n",
    "        team_df = csv_df[csv_df['TEAM_ID'] == team['id']]\n",
    "        for col in team_df.columns[9:]:\n",
    "            team_df['AV_'+ col] = team_df[col].rolling(window=10).mean()\n",
    "            team_df['AV_'+ col] = team_df['AV_'+ col]\n",
    "        head = list(team_df.columns.values)\n",
    "        if x == 1:\n",
    "            team_df.tail(1).to_csv(w_filename, header=head, index=False)\n",
    "            x = x+1\n",
    "\n",
    "        else:\n",
    "            team_df.tail(1).to_csv(w_filename, mode='a', header=False, index=False)\n",
    "most_recent_team_data('10-8-2020.csv', 'last_game_10-8-2020.csv', \"10/16/2019\", \"10/08/2020\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combines teams that play eachother and sorts data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_team_games(df, keep_method='home'):\n",
    "    '''Combine a TEAM_ID-GAME_ID unique table into rows by game. Slow.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : Input DataFrame.\n",
    "        keep_method : {'home', 'away', 'winner', 'loser', ``None``}, default 'home'\n",
    "            - 'home' : Keep rows where TEAM_A is the home team.\n",
    "            - 'away' : Keep rows where TEAM_A is the away team.\n",
    "            - 'winner' : Keep rows where TEAM_A is the losing team.\n",
    "            - 'loser' : Keep rows where TEAM_A is the winning team.\n",
    "            - ``None`` : Keep all rows. Will result in an output DataFrame the same\n",
    "                length as the input DataFrame.\n",
    "                \n",
    "        Returns\n",
    "        -------\n",
    "        result : DataFrame\n",
    "    '''\n",
    "    # Join every row to all others with the same game ID.\n",
    "    joined = pd.merge(df, df, suffixes=['_A', '_B'],\n",
    "                      on=['SEASON_ID', 'GAME_ID', 'GAME_DATE'])\n",
    "    # Filter out any row that is joined to itself.\n",
    "    result = joined[joined.TEAM_ID_A != joined.TEAM_ID_B]\n",
    "    # Take action based on the keep_method flag.\n",
    "    if keep_method is None:\n",
    "        # Return all the rows.\n",
    "        pass\n",
    "    elif keep_method.lower() == 'home':\n",
    "        # Keep rows where TEAM_A is the home team.\n",
    "        result = result[result.MATCHUP_A.str.contains(' vs. ')]\n",
    "    elif keep_method.lower() == 'away':\n",
    "        # Keep rows where TEAM_A is the away team.\n",
    "        result = result[result.MATCHUP_A.str.contains(' @ ')]\n",
    "    elif keep_method.lower() == 'winner':\n",
    "        result = result[result.WL_A == 'W']\n",
    "    elif keep_method.lower() == 'loser':\n",
    "        result = result[result.WL_A == 'L']\n",
    "    else:\n",
    "        raise ValueError(f'Invalid keep_method: {keep_method}')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses combine function\n",
    "count = 0\n",
    "for row in attempt.iterrows():\n",
    "    if (count == 0):\n",
    "        catch = attempt.loc[attempt['GAME_ID'] == row[1]['GAME_ID']]\n",
    "        catch = pd.DataFrame(catch)\n",
    "        combine = combine_team_games(catch)\n",
    "        combine.to_csv('combined_19-20.csv', index=False)\n",
    "        count = count + 1\n",
    "    else: \n",
    "        old_df = pd.read_csv('combined_19-20.csv')\n",
    "        catch = attempt.loc[attempt['GAME_ID'] == row[1]['GAME_ID']]\n",
    "        catch = pd.DataFrame(catch)\n",
    "        combine = combine_team_games(catch)\n",
    "        new_df = old_df.append(combine)\n",
    "        new_df.to_csv('combined_19-20.csv', index=False)\n",
    "#         count = count + 1\n",
    "#     if (count == 5):\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = pd.read_csv('combined_19-20.csv')\n",
    "# drops duplicates, sort by game date, and replace W with 1 and L with 0\n",
    "cleaned = clean.drop_duplicates(subset='GAME_ID')\n",
    "cleaned = cleaned.sort_values('GAME_DATE')\n",
    "cleaned['WL_A'] = cleaned['WL_A'].replace(['W','L'],[1,0])\n",
    "cleaned['WL_B'] = cleaned['WL_B'].replace(['W','L'],[1,0])\n",
    "cleaned.to_csv('combined_CLEANED_2019-2020.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculates zscores for each team + fits data to linear regression and decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('combined_CLEANED_2019-2020.csv')\n",
    "z_data = pd.DataFrame(columns = ['WL', 'PTS', 'FGM' , 'FGA', 'FG_PCT', 'FG3M', 'FG3A', 'FG3_PCT', 'FTM', 'FTA', 'FT_PCT', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PLUS_MINUS'])\n",
    "z_data['WL'] = data['WL_A']\n",
    "for column in z_data.columns[1:]:\n",
    "    z_data[column] = data['AV_' + column + '_A'] - data['AV_' + column + '_B']\n",
    "z_data = z_data.dropna()\n",
    "z_data.head()\n",
    "z_data.to_csv('z_scores_19-20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the logistic regression model and tests accuracy\n",
    "def performLogReg(dataframe):\n",
    "\n",
    "    # Update if new stats are added\n",
    "    featureColumns = ['PTS', 'FGM', 'FGA', 'FG3_PCT', 'FTA','REB', 'AST',  'STL', 'TOV']\n",
    "\n",
    "    X = dataframe[featureColumns] # Features\n",
    "    Y = dataframe['WL'] # Target Variable\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, shuffle=True)\n",
    "    logreg = LogisticRegression()\n",
    "\n",
    "    logreg.fit(X_train, Y_train)  # Fits model with data\n",
    "\n",
    "    Y_pred = logreg.predict(X_test)\n",
    "\n",
    "    confusionMatrix = metrics.confusion_matrix(Y_test, Y_pred)  # Diagonals tell you correct predictions\n",
    "\n",
    "    # Code below prints model accuracy information\n",
    "    print('Coefficient Information:')\n",
    "\n",
    "    for i in range(len(featureColumns)):  # Prints each feature next to its corresponding coefficient in the model\n",
    "\n",
    "        logregCoefficients = logreg.coef_\n",
    "\n",
    "        currentFeature = featureColumns[i]\n",
    "        currentCoefficient = logregCoefficients[0][i]\n",
    "\n",
    "        print(currentFeature + ': ' + str(currentCoefficient))\n",
    "\n",
    "    print('----------------------------------')\n",
    "\n",
    "    print(\"Accuracy:\", metrics.accuracy_score(Y_test, Y_pred))\n",
    "    print(\"Precision:\", metrics.precision_score(Y_test, Y_pred))\n",
    "    print(\"Recall:\", metrics.recall_score(Y_test, Y_pred))\n",
    "\n",
    "    print('----------------------------------')\n",
    "\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusionMatrix)\n",
    "\n",
    "    return logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"z_scores_17-18.csv\")\n",
    "df2 = pd.read_csv(\"z_scores_18-19.csv\")\n",
    "df3 = pd.read_csv(\"z_scores_19-20.csv\")\n",
    "df1 = df1.append(df2)\n",
    "df1 = df1.append(df3)\n",
    "performLogReg(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performDecTree(dataframe):\n",
    "    # Update if new stats are added\n",
    "    featureColumns = ['PTS', 'FGM', 'FGA', 'FG3_PCT', 'FTA','REB', 'AST',  'STL', 'TOV']\n",
    "\n",
    "    X = dataframe[featureColumns] # Features\n",
    "    Y = dataframe['WL'] # Target Variable\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=1)\n",
    "    \n",
    "    model = tree.DecisionTreeClassifier(max_depth=2)\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    Y_predict = model.predict(X_test)\n",
    "    print(accuracy_score(Y_test, Y_predict))\n",
    "    \n",
    "    print(pd.DataFrame(\n",
    "    confusion_matrix(Y_test, Y_predict),\n",
    "    columns=['L', 'W'],\n",
    "    index=['True L', 'True W']\n",
    "))\n",
    "\n",
    "performDecTree(df1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
