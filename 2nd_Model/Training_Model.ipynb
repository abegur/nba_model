{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nba_api.stats.static import teams\n",
    "from nba_api.stats.endpoints import leaguegamefinder\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from os import path\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(filename, start_date, end_date):\n",
    "    nba_teams = teams.get_teams()\n",
    "    if (path.exists(filename) != True):\n",
    "        \n",
    "        team_id = nba_teams[0]['id']\n",
    "        gamefinder = leaguegamefinder.LeagueGameFinder(date_from_nullable = start_date , date_to_nullable = end_date , team_id_nullable = team_id)\n",
    "        games = gamefinder.get_data_frames()[0]\n",
    "        games.to_csv(filename,index=False)\n",
    "        \n",
    "    if (path.exists(filename) == True):   \n",
    "        \n",
    "        old_df = pd.read_csv(filename)\n",
    "        last_id = old_df['TEAM_ID'][len(old_df)-1]\n",
    "        start_id = int(last_id) + 1\n",
    "        \n",
    "        while start_id <= 1610612766:\n",
    "            old_df = pd.read_csv(filename)\n",
    "            gamefinder = leaguegamefinder.LeagueGameFinder(date_from_nullable = start_date , date_to_nullable = end_date , team_id_nullable = start_id)\n",
    "            games = gamefinder.get_data_frames()[0]\n",
    "            new_df = old_df.append(games)\n",
    "            new_df.to_csv(filename, index=False)\n",
    "            start_id = start_id + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_handle(count, filename, start_date, end_date):\n",
    "    try:\n",
    "        print(\"-----try is running-----\")\n",
    "        # put csv name here\n",
    "        getData(filename, start_date, end_date)\n",
    "        count = 0\n",
    "        \n",
    "    except:\n",
    "        if count < 25:\n",
    "            print(\"-----exception handled-----\", count)\n",
    "            error_handle(count + 1,filename, start_date, end_date)\n",
    "        else:\n",
    "            print(\"-----max tries exceeded-----\")\n",
    "    \n",
    "    nba_teams = teams.get_teams()\n",
    "    csv_df = pd.read_csv(filename)\n",
    "    cdf = csv_df.sort_values(['TEAM_ABBREVIATION','GAME_DATE'] , ascending=[True, True])\n",
    "    cdf.to_csv(filename, index=False)\n",
    "    \n",
    "    return rolling_average_stats(filename, 'ten_day-' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#name of csv to read, name of csv to write\n",
    "def rolling_average_stats(r_filename, w_filename):  \n",
    "    print('Inside rolling_average_stats')\n",
    "    \n",
    "    nba_teams = teams.get_teams()\n",
    "    csv_df = pd.read_csv(r_filename)\n",
    "\n",
    "    list_points = []\n",
    "    list_team_points = []\n",
    "    x = 1\n",
    "    for team in nba_teams:\n",
    "        team_df = csv_df[csv_df['TEAM_ID'] == team['id']]\n",
    "        for col in team_df.columns[9:]:\n",
    "            team_df['AV_'+ col] = team_df[col].rolling(window=10).mean()\n",
    "            team_df['AV_'+ col] = team_df['AV_'+ col].shift(1) #add code here\n",
    "        head = list(team_df.columns.values)\n",
    "        if x == 1:\n",
    "#             new_df = team_df\n",
    "            team_df.to_csv(w_filename, header=head, index=False)\n",
    "            x = x+1\n",
    "\n",
    "        else:\n",
    "#             new_df.append(team_df)\n",
    "            team_df.to_csv(w_filename, mode='a', header=False, index=False)\n",
    "    combine_and_clean(w_filename, \"combined-\" + w_filename)\n",
    "    return (\"combined-\" + w_filename)\n",
    "#     z_data = get_zscore_for_one_year(combine_and_clean(w_filename, \"combined-\" + w_filename))\n",
    "#     z_data.to_csv(\"z_data_for_\" + \"combined-\" + w_filename)\n",
    "#     return \"z_data_for_\" + \"combined-\" + w_filename\n",
    "#     z_data.to_csv(\"z_data_for_\" + \"combined-\" + w_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_team_games(df, keep_method='home'):\n",
    "    '''Combine a TEAM_ID-GAME_ID unique table into rows by game. Slow.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : Input DataFrame.\n",
    "        keep_method : {'home', 'away', 'winner', 'loser', ``None``}, default 'home'\n",
    "            - 'home' : Keep rows where TEAM_A is the home team.\n",
    "            - 'away' : Keep rows where TEAM_A is the away team.\n",
    "            - 'winner' : Keep rows where TEAM_A is the losing team.\n",
    "            - 'loser' : Keep rows where TEAM_A is the winning team.\n",
    "            - ``None`` : Keep all rows. Will result in an output DataFrame the same\n",
    "                length as the input DataFrame.\n",
    "                \n",
    "        Returns\n",
    "        -------\n",
    "        result : DataFrame\n",
    "    '''\n",
    "    # Join every row to all others with the same game ID.\n",
    "    joined = pd.merge(df, df, suffixes=['_A', '_B'],\n",
    "                      on=['SEASON_ID', 'GAME_ID', 'GAME_DATE'])\n",
    "    # Filter out any row that is joined to itself.\n",
    "    result = joined[joined.TEAM_ID_A != joined.TEAM_ID_B]\n",
    "    # Take action based on the keep_method flag.\n",
    "    if keep_method is None:\n",
    "        # Return all the rows.\n",
    "        pass\n",
    "    elif keep_method.lower() == 'home':\n",
    "        # Keep rows where TEAM_A is the home team.\n",
    "        result = result[result.MATCHUP_A.str.contains(' vs. ')]\n",
    "    elif keep_method.lower() == 'away':\n",
    "        # Keep rows where TEAM_A is the away team.\n",
    "        result = result[result.MATCHUP_A.str.contains(' @ ')]\n",
    "    elif keep_method.lower() == 'winner':\n",
    "        result = result[result.WL_A == 'W']\n",
    "    elif keep_method.lower() == 'loser':\n",
    "        result = result[result.WL_A == 'L']\n",
    "    else:\n",
    "        raise ValueError(f'Invalid keep_method: {keep_method}')\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses combine function and cleans csv\n",
    "# ten_day_csv is the csv with the rolling ten day averages for a year\n",
    "# combined_csv is the returned csv with teams combined with their matchups\n",
    "def combine_and_clean(ten_day_csv, combined_csv):\n",
    "    print('Inside combine_and_clean')\n",
    "    \n",
    "    attempt = pd.read_csv(ten_day_csv,index_col=[0])\n",
    "    attempt = attempt.drop(['PTS','FGM','FGA','FG_PCT','FG3M','FG3A','FG3_PCT','FTM','FTA','FT_PCT','OREB','DREB','REB','AST','STL','BLK','TOV','PF', 'PLUS_MINUS'],axis=1)\n",
    "\n",
    "    count = 0\n",
    "    for row in attempt.iterrows():\n",
    "        if (count == 0):\n",
    "            catch = attempt.loc[attempt['GAME_ID'] == row[1]['GAME_ID']]\n",
    "            catch = pd.DataFrame(catch)\n",
    "            combine = combine_team_games(catch)\n",
    "            combine.to_csv(combined_csv, index=False)\n",
    "            count = count + 1\n",
    "        else: \n",
    "            old_df = pd.read_csv(combined_csv)\n",
    "            catch = attempt.loc[attempt['GAME_ID'] == row[1]['GAME_ID']]\n",
    "            catch = pd.DataFrame(catch)\n",
    "            combine = combine_team_games(catch)\n",
    "            new_df = old_df.append(combine)\n",
    "            new_df.to_csv(combined_csv, index=False)\n",
    "    \n",
    "    clean = pd.read_csv(combined_csv)\n",
    "    # drops duplicates, sort by game date, and replace W with 1 and L with 0\n",
    "    cleaned = clean.drop_duplicates(subset='GAME_ID')\n",
    "    cleaned = cleaned.sort_values('GAME_DATE')\n",
    "    cleaned['WL_A'] = cleaned['WL_A'].replace(['W','L'],[1,0])\n",
    "    cleaned['WL_B'] = cleaned['WL_B'].replace(['W','L'],[1,0])\n",
    "    cleaned.to_csv(combined_csv, index=False)\n",
    "    return combined_csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zscore_for_one_year(cleaned_csv):\n",
    "    print(\"Inside get_zscore_for_one_year\")\n",
    "    \n",
    "    data = pd.read_csv(cleaned_csv)\n",
    "    z_data = pd.DataFrame(columns = ['WL', 'PTS', 'FGM' , 'FGA', 'FG_PCT', 'FG3M', 'FG3A', 'FG3_PCT', 'FTM', 'FTA', 'FT_PCT', 'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PLUS_MINUS'])\n",
    "    z_data['WL'] = data['WL_A']\n",
    "    for column in z_data.columns[1:]:\n",
    "        z_data[column] = data['AV_' + column + '_A'] - data['AV_' + column + '_B']\n",
    "    z_data = z_data.dropna()\n",
    "    return z_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zscores(year1_cleaned_csv, year2_cleaned_csv, year3_cleaned_csv):\n",
    "    \n",
    "    df1 = get_zscore_for_one_year(year1_cleaned_csv)\n",
    "    df2 = get_zscore_for_one_year(year2_cleaned_csv)\n",
    "    df3 = get_zscore_for_one_year(year3_cleaned_csv)\n",
    "    \n",
    "    df1 = df1.append(df2)\n",
    "    df1 = df1.append(df3)\n",
    "    df1.to_csv(\"all_zscores.csv\", index=False)\n",
    "    return performLogReg(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the logistic regression model and tests accuracy\n",
    "def performLogReg(dataframe):\n",
    "\n",
    "    # Update if new stats are added\n",
    "    featureColumns = ['PTS', 'FGM', 'FGA', 'FG3_PCT', 'FTA','REB', 'AST',  'STL', 'TOV']\n",
    "\n",
    "    X = dataframe[featureColumns] # Features\n",
    "    Y = dataframe['WL'] # Target Variable\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, shuffle=True)\n",
    "    logreg = LogisticRegression()\n",
    "\n",
    "    logreg.fit(X_train, Y_train)  # Fits model with data\n",
    "    filename = 'finalized_model.sav'\n",
    "    pickle.dump(logreg, open(filename, 'wb'))\n",
    "\n",
    "    Y_pred = logreg.predict(X_test)\n",
    "\n",
    "    confusionMatrix = metrics.confusion_matrix(Y_test, Y_pred)  # Diagonals tell you correct predictions\n",
    "\n",
    "    # Code below prints model accuracy information\n",
    "    print('Coefficient Information:')\n",
    "\n",
    "    for i in range(len(featureColumns)):  # Prints each feature next to its corresponding coefficient in the model\n",
    "\n",
    "        logregCoefficients = logreg.coef_\n",
    "\n",
    "        currentFeature = featureColumns[i]\n",
    "        currentCoefficient = logregCoefficients[0][i]\n",
    "\n",
    "        print(currentFeature + ': ' + str(currentCoefficient))\n",
    "\n",
    "    print('----------------------------------')\n",
    "\n",
    "    print(\"Accuracy:\", metrics.accuracy_score(Y_test, Y_pred))\n",
    "    print(\"Precision:\", metrics.precision_score(Y_test, Y_pred))\n",
    "    print(\"Recall:\", metrics.recall_score(Y_test, Y_pred))\n",
    "\n",
    "    print('----------------------------------')\n",
    "\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusionMatrix)\n",
    "\n",
    "    return logreg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    logreg = get_zscores(error_handle(0, \"2017-18.csv\", \"10/17/2017\", \"06/17/2018\"), error_handle(0, \"2018-19.csv\", \"10/16/2018\", \"06/13/2019\"), error_handle(0, \"2019-20.csv\", \"10/22/2019\", \"10/11/2020\"))\n",
    "    print(logreg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----try is running-----\n",
      "Inside rolling_average_stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhibegur/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/abhibegur/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside combine_and_clean\n",
      "-----try is running-----\n",
      "Inside rolling_average_stats\n",
      "Inside combine_and_clean\n",
      "-----try is running-----\n",
      "Inside rolling_average_stats\n",
      "Inside combine_and_clean\n",
      "Inside get_zscore_for_one_year\n",
      "Inside get_zscore_for_one_year\n",
      "Inside get_zscore_for_one_year\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'performLogRed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-abc9177d04ad>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mlogreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_zscores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"2017-18.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"10/17/2017\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"06/17/2018\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"2018-19.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"10/16/2018\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"06/13/2019\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"2019-20.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"10/22/2019\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"10/11/2020\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogreg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-0fe2e15e6f79>\u001b[0m in \u001b[0;36mget_zscores\u001b[0;34m(year1_cleaned_csv, year2_cleaned_csv, year3_cleaned_csv)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"all_zscores\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mperformLogRed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'performLogRed' is not defined"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient Information:\n",
      "PTS: 0.10149289540987554\n",
      "FGM: -0.06212808904733416\n",
      "FGA: -0.12129716506419759\n",
      "FG3_PCT: -0.9678254447923506\n",
      "FTA: -0.07701460465724103\n",
      "REB: 0.11634255442170666\n",
      "AST: -0.01349962145239629\n",
      "STL: 0.1338439910065507\n",
      "TOV: -0.08345978710559933\n",
      "----------------------------------\n",
      "Accuracy: 0.6287425149700598\n",
      "Precision: 0.6552962298025135\n",
      "Recall: 0.7556935817805382\n",
      "----------------------------------\n",
      "Confusion Matrix:\n",
      "[[160 192]\n",
      " [118 365]]\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# print(performLogReg(pd.read_csv(\"all_zscores.csv\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performLogReg(get_zscore_for_one_year('combined-ten_day-2017-18.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
